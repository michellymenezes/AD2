---
title: "Lab 3 - Parte 2"
author: "Martha Michelly"
date: "20 de fevereiro de 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(reshape2)

library(rpart)
library(caret)
```

Esta é a continuação do laboratório 3. Aqui damos continuidade ao tema "evasão no primeiro período". Na parte 1 foi feita a análise descritiva dos dados, nesta parte 2 estaremos utilizando algoritmos de classificação para tentar prever evasão de alunos no curso de computação ao fim do primeiro período.

### Separação dos dados em treino e teste

```{r, message=FALSE}
dados = read.csv("treino_classificacao_v2.csv")

dados.treino = subset(dados, MAT_TUR_ANO > 2010 & (MAT_TUR_ANO < 2015))
dados.treino = rbind(dados.treino, subset(dados, MAT_TUR_ANO == 2015 & MAT_TUR_PERIODO == 1))

dados.teste = subset(dados, MAT_TUR_ANO == 2015 & MAT_TUR_PERIODO == 2)

dados.treino = dados.treino %>% select(-MAT_TUR_DIS_DISCIPLINA, -MAT_TUR_ANO, -MAT_TUR_PERIODO) %>% filter(!is.na(MAT_MEDIA_FINAL))
dados.teste = dados.teste %>% select(-MAT_TUR_DIS_DISCIPLINA, -MAT_TUR_ANO, -MAT_TUR_PERIODO) %>% filter(!is.na(MAT_MEDIA_FINAL))

alunos.evadiu.treino = dados.treino %>%
  group_by(MAT_ALU_MATRICULA) %>%
  summarise(evadiu = any(EVADIU))

alunos.evadiu.teste = dados.teste %>%
  group_by(MAT_ALU_MATRICULA) %>%
  summarise(evadiu = any(EVADIU))

dados.treino <- dados.treino %>%
  group_by(MAT_ALU_MATRICULA, disciplina)  %>%
  filter(MAT_MEDIA_FINAL == max(MAT_MEDIA_FINAL)) %>%
  ungroup() %>%
  select(MAT_ALU_MATRICULA, disciplina, MAT_MEDIA_FINAL) %>% 
  mutate(disciplina = as.factor(gsub(" ",".",disciplina))) %>%
  dcast(MAT_ALU_MATRICULA ~ disciplina, mean) %>%
  merge(alunos.evadiu.treino)

dados.teste <- dados.teste %>%
  group_by(MAT_ALU_MATRICULA, disciplina)  %>%
  filter(MAT_MEDIA_FINAL == max(MAT_MEDIA_FINAL)) %>%
  ungroup() %>%
  select(MAT_ALU_MATRICULA, disciplina, MAT_MEDIA_FINAL) %>% 
  mutate(disciplina = as.factor(gsub(" ",".",disciplina))) %>%
  dcast(MAT_ALU_MATRICULA ~ disciplina, mean) %>%
  merge(alunos.evadiu.teste)
```

### Adicionando atributos

Percebemos que algumas notas de disciplinas estão com valores vazios. Para que não precisemos remover toda a linha do data frame, vamos realizar imputação de dados. Decidimos que os valores vazios em disciplinas serão substituídos pelo valor da média das notas presentes.

```{r}
for(i in 1:nrow(dados.treino)){
  for(j in 1:ncol(dados.treino)){
    if(is.na(dados.treino[i,j])){
      dados.treino[i, j] = sum(dados.treino[i,2:7], na.rm = T)/(6-sum(is.na(dados.treino[i,2:7])))
    }
    if(i <= nrow(dados.teste)){
      if(is.na(dados.teste[i,j])){
        dados.teste[i, j] = sum(dados.treino[i,2:7], na.rm = T)/(6-sum(is.na(dados.treino[i,2:7])))
      }
    }
  }
}

head(dados.treino)
```

Para um segundo atributo, decidimos que será uma variável categórica. Se o aluno reprovou Programação I ou Lab. de Programação I, o valor será TRUE, caso contrário, FALSE.

```{r}
dados.treino$Programacao[dados.treino$Programação.I >= 5 & dados.treino$Laboratório.de.Programação.I >= 5 ] = F
dados.teste$Programacao[dados.teste$Programação.I >= 5 & dados.teste$Laboratório.de.Programação.I >= 5 ] = F

dados.treino$Programacao[dados.treino$Programação.I < 5 & dados.treino$Laboratório.de.Programação.I < 5 ] = T
dados.teste$Programacao[dados.teste$Programação.I < 5 & dados.teste$Laboratório.de.Programação.I < 5 ] = T

dados.treino$Programacao[is.na(dados.treino$Programacao)] = T
dados.teste$Programacao[is.na(dados.teste$Programacao)] = T
```

### Treino - Modelos de regressão logística

```{r}
set.seed(123)

dados.treino$evadiu = as.factor(dados.treino$evadiu)
dados.teste$evadiu = as.factor(dados.teste$evadiu)

dados.treino$Programacao = as.factor(dados.treino$Programacao)
dados.teste$Programacao = as.factor(dados.teste$Programacao)

model.gml = train(evadiu ~. -MAT_ALU_MATRICULA,
                   data=dados.treino,
                   method="glm",
                   family="binomial")
```

### Treino - Modelos de árvore de decisão

```{r}
dtf2 = select(dados.treino, -Programacao)
dtf2$Programacao[dados.treino$Programacao==T] = 1
dtf2$Programacao[dados.treino$Programacao==F] = 0
model.tree = rpart(evadiu ~ . -MAT_ALU_MATRICULA, data=dtf2)
```

### Interpretação de coeficientes da regressão

Vemos abaixo que as variáveis mais significativas são Leitura e Produção de Texto de Introdução à Computação. Essas variáveis apresentam os menores p-valores, o que para mim não faz muito sentido. Talvez essa importância seja resultado da imputação dos dados.

```{r}
summary(model.gml)
```

### Acurácia, precision e recall no treino e teste

* **Acurácia**: proporção de observações corretamente classificadas. (TP+TN)/(TP+TN+FP+FN).
* **Precisão**: quantas das observaçoes preditas como positivas são realmente positivas. TP/(TP+FP).
* **Recall**: quantas observaçoes positivas foram corretamente classificadas. TP/(TP+FN).

#### Regressão logística

```{r}
dados.teste$predicao.gml = predict(model.gml, dados.teste)


temp = dados.teste %>% select(evadiu, predicao.gml)

TP = temp %>% filter(evadiu == TRUE, predicao.gml == TRUE) %>% nrow()
TN = temp %>% filter(evadiu == FALSE, predicao.gml == FALSE) %>% nrow()
FP = temp %>% filter(evadiu == FALSE, predicao.gml == TRUE) %>% nrow() 
FN = temp %>% filter(evadiu == TRUE, predicao.gml == FALSE) %>% nrow()

print(paste('Accuracy', (TP + TN)/(TP+TN+FP+FN)))
print(paste('Precision', TP / (TP + FP)))
print(paste('Recall', TP / (TP + FN)))
```

#### Árvore de decisão

```{r}
tst2 = select(dados.teste, -Programacao)
tst2$Programacao[dados.teste$Programacao==T] = 1
tst2$Programacao[dados.teste$Programacao==F] = 0
predicao.tree <- as.data.frame(predict(model.tree, tst2))

temp = apply(predicao.tree['TRUE'], 2, FUN = function(x){return(x > 0.5)})
tst2$predicao.tree <- as.factor(temp)

temp = tst2 %>% select(evadiu, predicao.tree)

TP = temp %>% filter(evadiu == TRUE, predicao.tree == TRUE) %>% nrow()
TN = temp %>% filter(evadiu == FALSE, predicao.tree == FALSE) %>% nrow()
FP = temp %>% filter(evadiu == FALSE, predicao.tree == TRUE) %>% nrow() 
FN = temp %>% filter(evadiu == TRUE, predicao.tree == FALSE) %>% nrow()


print(paste('Accuracy', (TP + TN)/(TP+TN+FP+FN)))
print(paste('Precision', TP / (TP + FP)))
print(paste('Recall', TP / (TP + FN)))
```

### Controle overfitting usando validação-cruzada

#### Regressão Logistica

##### Ridge

O modelo de regressão para ridge é ajustado chamando a função glmnet com alpha igual a 0. Glmnet desenvolve modelos em uma grade com cerca de 100 valores de lambda, como podemos ver no gráfico abaixo. Quando log de lambda é 4, todos os coeficientes são essencialmente zero. Então, à medida que relaxamos lambda, os coeficientes crescem de distanciando de zero.

```{r}
library(glmnet)

set.seed(825)

model.ridge = glmnet(x = model.matrix( ~ . -MAT_ALU_MATRICULA -evadiu, dados.treino),
                y = dados.treino$evadiu,
                alpha = 0,
                family = 'binomial')

plot(model.ridge, xvar = "lambda", label = T)
```

Para selecionar um modelo ridge executamos a função **cv.glmnet** que fará validação cruzada. Na parte superior do gráfico é possível ver quantos coeficientes de variáveis não-zero estão no modelo. Há todas as 7 variáveis no modelo, 6 variáveis e o intercept, e nenhum coeficiente é zero.

No início, o desvio binomial é mais alto e os coeficientes são pequenos até que, em algum ponto, ele se eleva e o intervalo é reduzido.

```{r}
cv.ridge <- cv.glmnet(model.matrix( ~ . -MAT_ALU_MATRICULA -evadiu, dados.treino), y=dados.treino$evadiu, alpha=0, family="binomial")

plot(cv.ridge, sub = T)
```

##### Lasso

O modelo de regressão para lasso é ajustado chamando a função glmnet com alpha igual a 1. 

```{r}
model.lasso = glmnet(x = model.matrix( ~ . -MAT_ALU_MATRICULA -evadiu, dados.treino),
                y = dados.treino$evadiu,
                alpha = 1,
                family = 'binomial')
plot(model.lasso, xvar = "lambda", label = T)
```

O plot tem várias opções, o desvio, por exemplo, está relacionado fraction deviance explained, que é equivalente a r-quadrado em regressão. Notamos que muito do r-quadrado foi explicado por basicamente duas variáveis, representadas pelas cores verde e azul claro. 

```{r}
plot(model.lasso,xvar="dev",label=TRUE)
```

Coeficientes podem ser extraídos do glmmod. Aqui mostrado com 2 variáveis selecionadas. sendo elas Introdução.à.Computação e Leitura.e.Produção.de.Textos. Decidimos então que o melhor modelo para regressão logística será composto apenas por essas duas variáveis intependentes.

```{r}
coef(model.lasso)[,10]
```

Assim como em ridge, realizamos o processo para visualização da validação cruzada.

```{r}
cv.lasso <- cv.glmnet(model.matrix( ~ . -MAT_ALU_MATRICULA -evadiu, dados.treino), y=dados.treino$evadiu, alpha=1, family="binomial")
plot(cv.lasso)
```

E definimos o **novo melhor modelo de regressão logística**.

```{r}
# novo modelo
fitControl = trainControl(method = "cv", number = 10)
best.glm.model <- model.lasso <- train(evadiu ~ Introdução.à.Computação + Leitura.e.Produção.de.Textos,
                   data=dados.treino,
                   method="glm",
                   family="binomial",
                   preProcess = c('scale', 'center'),
                   trControl = fitControl,
                   na.action = na.omit)
```

#### Árvore de decisão

Para a árvore de decisão, é utilizada a função rpart.control, definindo um valor máximo de altura igual a 30 (valor recomendado).

```{r}
dt.control = rpart.control(maxdepth=30)

model.tree = rpart(evadiu ~ . -MAT_ALU_MATRICULA,
                           data=dtf2,
                           method="class",
                           control=dt.control)

printcp(model.tree)

best.tree = prune(model.tree,
 + model.tree$cptable[which.min(model.tree$cptable[,"xerror"]),"CP"])
```

### Acurácia, precision e recall da validação-cruzada e teste (para os melhores modelos)

#### Regressão Logística

```{r}
dados.teste$best.glm.prediction <- predict(best.glm.model, dados.teste)
temp = dados.teste %>% select(evadiu, best.glm.prediction)

TP = temp %>% filter(evadiu == TRUE, best.glm.prediction == TRUE) %>% nrow()
TN = temp %>% filter(evadiu == FALSE, best.glm.prediction == FALSE) %>% nrow()
FP = temp %>% filter(evadiu == FALSE, best.glm.prediction == TRUE) %>% nrow() 
FN = temp %>% filter(evadiu == TRUE, best.glm.prediction == FALSE) %>% nrow()

print(paste('Accuracy', (TP + TN)/(TP+TN+FP+FN)))
print(paste('Precision', TP / (TP + FP)))
print(paste('Recall', TP / (TP + FN)))
```

#### Árvore de decisão

```{r}
predicao.best.tree = as.data.frame(predict(best.tree, tst2))
temp = apply(predicao.best.tree['TRUE'], 2, FUN = function(x){return(x > 0.5)})
tst2$predicao.best.tree = as.factor(temp)

temp = tst2 %>% select(evadiu, predicao.best.tree)

TP = temp %>% filter(evadiu == TRUE, predicao.best.tree == TRUE) %>% nrow()
TN = temp %>% filter(evadiu == FALSE, predicao.best.tree == FALSE) %>% nrow()
FP = temp %>% filter(evadiu == FALSE, predicao.best.tree == TRUE) %>% nrow() 
FN = temp %>% filter(evadiu == TRUE, predicao.best.tree == FALSE) %>% nrow()

print(paste('Accuracy', (TP + TN)/(TP+TN+FP+FN)))
print(paste('Precision', TP / (TP + FP)))
print(paste('Recall', TP / (TP + FN)))
```

### Aplicação do melhor modelo

```{r}
pessoal.dados <- data.frame(Introdução.à.Computação=8, Leitura.e.Produção.de.Textos = 8)
pessoal.predicao <- predict(best.glm.model, pessoal.dados)
pessoal.predicao
```
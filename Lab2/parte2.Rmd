---
title: "Lab 2 - Parte 2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(GGally)
library(ggplot2)
library(corrplot)
library(RColorBrewer)

```
## Apresentação dos dados

Nesse laboratório utilizamos dados referentes aos alunos que já concluíram o curso de Ciência da Computação - UFCG. Nele se encontram, de cada aluno, todas as médias finais obtidas em cada disciplina (5-10), assim como o coeficiente de rendimento acadêmico (cra, ~4-10).

Queremos realizar análises de regressão utilizando as disciplinas dos dois primeiros períodos e cra na tentativa de responder a seguinte pergunta:

  ***O desempenho dos alunos nos dois primeiros períodos consegue explicar, em algum grau, seus desempenhos no curso como um todo?***


Para isso, construiremos um modelo de regressão com disciplinas do primeiro e segundo período. Ao longo desse documento iremos responder perguntas a respeito do modelo e realizar comparações. Logo abaixo um breve resumo de como se distribuem as variáveis quando relacionadas e seus respectivos coeficientes de correlação.

*Legenda*

* ***Cálculo.1***: Cálculo Diferencial e Integral I - Período 1
* ***Vetorial***: Álgebra Vetorial e Geometria Analítica - Período 1
* ***LPT***: Leitura e Produção de Textos - Período 1
* ***P1***: Programação I - Período 1
* ***LP1***: Laboratório de Programação I - Período 1
* ***IC***: Introdução à Computação - Período 1
* ***Cálculo.2***: Cálculo Diferencial e Integral II - Período 2
* ***Discreta***: Matemática Discreta - Período 2
* ***P2***: Programação II - Período 2
* ***LP2***: Laboratório de Programação II - Período 2
* ***Grafos***: Teoria dos Grafos - Período 2
* ***Física.3***: Fundamentos de Física Clássica - Período 2


```{r, warning=FALSE, fig.width=22, fig.height=18}
graduados = read.csv("graduados_disciplinas.csv")

graduados = graduados[, c("Cálculo.Diferencial.e.Integral.I",  "Álgebra.Vetorial.e.Geometria.Analítica", "Leitura.e.Produção.de.Textos", "Programação.I", "Laboratório.de.Programação.I", "Introdução.à.Computação", "Cálculo.Diferencial.e.Integral.II", "Matemática.Discreta", "Programação.II", "Laboratório.de.Programação.II", "Teoria.dos.Grafos", "Fundamentos.de.Física.Clássica", "cra")]

colnames(graduados) = c("Cálculo.1", "Vetorial", "LPT", "P1", "LP1", "IC", "Cálculo.2", "Discreta", "P2", "LP2", "Grafos", "Física.3", "cra")

ggpairs(na.omit(graduados), lower = list(continuous = "smooth"), upper = list(continuous = wrap("cor", size = 10)))
```

```{r, fig.width=18, fig.height=10}
# ggcorr(graduados1[, 2:8], geom = "circle", nbreaks = 5)
# ggcorr(graduados1[, 2:8], nbreaks = 5,  label = TRUE, label_size = 3, label_round = 2, label_alpha = TRUE)

```
### Um modelo de regressão múltipla com todas as variáveis é plausível para explicar a variação em y? Em que grau?

Para responder esta pergunta criamos um modelo de regressão linear múltipla que englobe todas disciplinas como variáveis independentes e o cra como variável dependente. Após a criação do modelo, obtemos um resumo do mesmo com suas principais características relacionadas a efetividade.

```{r}
rl = lm(cra ~ ., data = graduados)

summary(rl)
```

Utilizamos o Residual standart error (RSE) para interpretar parte do nosso modelo. RSE é o desvio padrão dos resíduos que descreve a variabilidade referente ao modelo de regressão utilizado. Queremos que o valor RSE seja o menor possível. O RSE do modelo tem valor igual a 0.5046.

Uma segunda variável que utilizamos é o R-quadrado que apresenta valor referente ao coeficiente de determinação, ela varia entre 0-1 e indica quanto o modelo consegue explicar o valor observado, no nosso caso, o cra. Quanto maior o R-quadrado, melhor, significando que o modelo é mais explicativo. Existe um tendência de que quanto mais variáveis o modelo possuir, maior o seu poder explicativo, incentivando a inserção de muitas variáveis e para combater isso existe o R-quadrado ajustado. R-quadrado ajustado funciona da mesma maneira que o R-quadrado, com a diferença de que ele sofre penalização se há inclusão de variáveis com muito pouco poder explicativo. Para todos os modelos deste documento estaremos utilizando valores relacionados ao R-quadrado ajustado para medir o poder de explicação dos mesmos.

Interpretandos os dados acima temos que o R-quadrado ajustado tem valor igual a 0.6474, isso signigica que 64.74% do cra consegue ser explicado pelas variáveis independentes presentes no modelo. Então, sim, o modelo explica parte da variável dependente em mais de 50%.

### Todas as variáveis são úteis para o modelo de regressão?

Apesar de o modelo explicar a variável dependente em quase 67%, nem todas as variáveis independentes que fazem parte dele apresentam influência considerável. Neste documento, utilizaremos dois principais valores para avaliar a utilidade e significância de uma variável independente presente em um modelo: seu coeficiente (relacionado a magnitude) e p-valor.

O coeficiente de uma variável é referênte ao poder de influência que ela tem na variável dependente. O p-valor é referente a probabilidade de exisência por chance, queremos que este valor seja o menor possível para que a variável seja considerada importante para o modelo. 

Disciplinas como Física 3, Cálculo 2, Cálculo 1 etc, apresentam baixo coeficiente e p-valor elevado. Essas variáveis influenciam minimamente e não são consideradas úteis para o modelo. Portanto, nem todas as variáveis são úteis para o modelo de regressão apresentado.

### Se a resposta para a pergunta anterior foi não, construa um novo modelo sem essas variáveis e o compare ao modelo com todas as variáveis (e.g. em termos de R2 e RSE).

Selecionaremos variáveis baseadas em seus coeficientes e p-valor. Além disso, quando duas variáveis possuírem um alto coeficiente de correlação**, removeremos uma delas, já que váriáveis muito correlacionadas inserem redundância no modelo e podem proporcionar geração de valores incosistentes. Utilizaremos o summary do modelo e o correlograma abaixo para extrair e analisar esses valores.

***Um valor será considerado alto quando for >= 0.65. Valor escolhido com base na comparação relativa de coeficientes obtidos.*

```{r, fig.width=9, fig.height=7}
M = cor(na.omit(graduados[,1:12]))

corrplot(M, type = "lower", title = "Correlação de disciplinas",  order="hclust", col=brewer.pal(n=7, name="PuOr"), addCoef.col = "black", tl.col="black", tl.srt=45, mar=c(0,0,1,0) )
# 
# ggplot(graduados1, aes(graduados1$IC, graduados1$cra)) +  
#   geom_point(alpha = 0.1, position = position_jitter(width = 0.3), color="purple4") + 
#   labs(title="Previsão do modelo", x= "Nota em IC", y="CRA") +  
#   geom_line(aes(y = predict(rl1, graduados1)), colour = "red")



```

Iniciaremos removendo variáveis com alto coeficiente de correlação:

* O coeficiente de correlação de P1 e LP1 é igual a 0.77, decidimos manter P1 porque apresenta coeficiente (-0.02593) mais significativo e menor p-valor (0.73660).
* O coeficiente de correlação de P2 e Grafos é igual a 0.65, decidimos manter P2 porque apresenta coeficiente (0.29214) mais significativo e menor p-valor (0.00293).
* O coeficiente de correlação de LP2 e Discreta é igual a 0.65, decidimos manter Discreta porque apresenta coeficiente (0.23935) mais significativo e menor p-valor (9.63e-05).

Agora removemos as variáveis menos significativas considerando menores valores referentes ao coeficiente e maiors referentes ao p-valor:

* Cálculo.1 - coeficiente: 0.02121 / p-valor: 0.66661
* Cálculo.2 - coeficiente: -0.00100 / p-valor: 0.98499
* Física.3 - coeficiente: -0.01024 / p-valor: 0.86745

Sendo assim, nosso modelo fica da seguinte maneira:

```{r}
graduados = graduados[, c("LPT", "P1", "IC", "Vetorial", "Discreta", "P2", "cra")]
rl = lm(cra ~ ., data = graduados)

summary(rl)
```

O modelo agora apresenta um R-quadrado ajustado mais elevado, com valor igual a 0.5921, ou seja, ele explica em 59.21% a variável dependente. Por outro lado, o RSE teve seu valor elevado para 0,5342. Apesar disso, devido ao fato de que removemos variáveis, a quantidade de linhas com valores nulos diminuiu, aumentanto o tamanho da amostra e, consequentemente, a quantidade de graus de liberdade. 

### Analise os plots de resíduos de cada variável e veja se algum (um ou mais) deles indica não aleatoriedade dos erros.

```{r}

```
### Que período consegue explicar melhor o desempenho final (primeiro ou segundo)?

```{r}
graduados1 = graduados[,c("Vetorial", "LPT", "P1", "IC", "cra")]
graduados2 = graduados[, c("Discreta", "P2", "cra")]

graduados1 = na.omit(graduados1)
graduados2 = na.omit(graduados2)

rl1 = lm(cra ~ ., data = graduados1)
rl2 = lm(cra ~ ., data = graduados2)

summary(rl1)
summary(rl2)
```

### Use o modelo para predizer o seu próprio desempenho e compare a predição com o seu CRA atual. Comente o resultado.
---
title: "Lab 2 - Parte 3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library()
library(caret)
```

1. Usando todas as variáveis disponíveis (disciplinas do primeiro e segundo período), use validação cruzada (nos dados de treino) para tunar um modelo de regressão Ridge.
2. Mesmo que o item acima mas usando um modelo de regressão Lasso.
3. Compare os dois modelos nos dados de teste em termos de RMSE.
4. Quais as variáveis mais importantes segundo o modelo de regressão Lasso? Alguma variável foi descartada? Quais?
5. Re-treine o melhor modelo (dessa vez nos dados de treino sem validação cruzada) e reporte o RMSE no teste.
6. Use o modelo treinado em 6 e aplique nos dados de teste que vamos disponibilizar.
7. Crie novos atributos a partir dos existentes para tentar melhorar o seu modelo.


```{r}
dados_treino = read.csv("p1p2.graduados_treino.csv")
dados_teste = read.csv("p1p2.graduados_teste.csv")

for(i in 1:nrow(dados_treino)){
  for(j in 1:ncol(dados_treino)){
    if(is.na(dados_treino[i,j])){
      dados_treino[i, j] = dados_treino$cra[i]
    }
    if(i <= nrow(dados_teste)){
      if(is.na(dados_teste[i,j])){
        dados_teste[i, j] = dados_teste$cra[i]
      }
    }
  }
}
```

### Modelo de regressão Ridge

```{r}
ridge <- train(cra ~., data = dados_treino,
               method='ridge')
ridge
```

```{r}
ridge.pred <- predict(ridge, dados_teste)

```

```{r}
set.seed(825)
fitControl <- trainControl(method = "cv",
                           number = 10)
# Set seq of lambda to test
lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=100))

ridge <- train(cra~., data = dados_treino,
               method='ridge',
               trControl = fitControl,
                tuneGrid = lambdaGrid,
               preProcess=c('center', 'scale')
)

ridge
predict(ridge$finalModel, type='coef', mode='norm')$coefficients[13,]

```


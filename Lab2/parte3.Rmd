---
title: "Lab 2 - Parte 3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(caret)
```

2. Mesmo que o item acima mas usando um modelo de regressão Lasso.
3. Compare os dois modelos nos dados de teste em termos de RMSE.
4. Quais as variáveis mais importantes segundo o modelo de regressão Lasso? Alguma variável foi descartada? Quais?
5. Re-treine o melhor modelo (dessa vez nos dados de treino sem validação cruzada) e reporte o RMSE no teste.
6. Use o modelo treinado em 6 e aplique nos dados de teste que vamos disponibilizar.
7. Crie novos atributos a partir dos existentes para tentar melhorar o seu modelo.


```{r}
dados_treino = read.csv("p1p2.graduados_treino.csv")
dados_validacao = read.csv("p1p2.graduados_validacao.csv")

dados_treino = dados_treino[,2:15]
dados_validacao = dados_validacao[,2:15]

for(i in 1:nrow(dados_treino)){
  for(j in 1:ncol(dados_treino)){
    if(is.na(dados_treino[i,j])){
      dados_treino[i, j] = dados_treino$cra[i]
    }
    if(i <= nrow(dados_validacao)){
      if(is.na(dados_validacao[i,j])){
        dados_validacao[i, j] = dados_validacao$cra[i]
      }
    }
  }
}
```

## Modelo de regressão Ridge

Iniciaremos utilizando o método de regularização Ridge Regression, que suaviza atributos relacionados e que aumentam o ruído no modelo. Porque queremos encontrar o bom valor lambda para o modelo, utilizamos nos dados de treino a função *train* para escolher aquele com menor RMSE dentre 100 possíveis valores lambda.

```{r warning=FALSE, message=FALSE}
set.seed(825)
fitControl <- trainControl(method = "cv",
                           number = 10)

lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=100))

ridge <- train(cra~., data = dados_treino[,2:14],
               method='ridge',
               trControl = fitControl,
                tuneGrid = lambdaGrid,
               preProcess=c('center', 'scale')
)
```

Abaixo vemos a sequência de valores obtidos e uma representação gráfica do mesmo. 

```{r warning=FALSE, message=FALSE}
ridge
plot(ridge)
```

Em seguida, realizamos a predição dos dados, mas agora utilizando os dados de teste. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos. 

```{r}
ridge.pred <- predict(ridge, dados_validacao[,2:14])

ridge.pred <- data.frame(pred = ridge.pred, obs = dados_validacao$cra)
ggplot(ridge.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação")
```

O RMSE alto indica que o erro na predição foi alto. Ao utlizar a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.449. 

```{r}
round(defaultSummary(ridge.pred), digits = 3)
```

```{r}
##treino sem cross val.: remover fitControl

##predict(ridge$finalModel, type='coef', mode='norm')$coefficients[13,]

```
O RMSE alto indica que o erro na predição foi alto. O que acontece é que, por conta dos outliers, o modelo se ajusta bem a boa parte dos dados tendo como consequência grandes erros na previsão alguns valores. Dependendo do caso, isso pode indicar que a regressão não seria a melhor técnica para resolver o problema.

## Modelo de regressão Lasso

```{r}

lasso <- train(cra~., data = dados_treino[,2:14],
               method='lasso',
                tuneLength = 10,
               preProcess=c('center', 'scale')
)

plot(lasso)
lasso

varImp(lasso)

```


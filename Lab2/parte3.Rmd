---
title: "Lab 2 - Parte 3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(corrplot)
library(RColorBrewer)
```

## Apresentação dos dados

Como continuação da Parte 2, nesse fase estaremos criando modelos de regressão, comparando-os e realizando predição de dados. Continuamos trabalhando com disciplinas dos dois primeiros semestres para a criação de um modelo que consiga calcular o cra de uma determinada matrícula. Para isso dividimos os dados em treino, validação e teste. 

*Legenda*

* ***Cálculo.1***: Cálculo Diferencial e Integral I - Período 1
* ***Vetorial***: Álgebra Vetorial e Geometria Analítica - Período 1
* ***LPT***: Leitura e Produção de Textos - Período 1
* ***P1***: Programação I - Período 1
* ***LP1***: Laboratório de Programação I - Período 1
* ***IC***: Introdução à Computação - Período 1
* ***Cálculo.2***: Cálculo Diferencial e Integral II - Período 2
* ***Discreta***: Matemática Discreta - Período 2
* ***P2***: Programação II - Período 2
* ***LP2***: Laboratório de Programação II - Período 2
* ***Grafos***: Teoria dos Grafos - Período 2
* ***Física.3***: Fundamentos de Física Clássica - Período 2

```{r}
dados_treino = read.csv("p1p2.graduados_treino.csv")
dados_validacao = read.csv("p1p2.graduados_validacao.csv")
dados_teste = read.csv("test.csv")

colnames(dados_teste) = c("matricula", "Cálculo.1", "Vetorial", "LPT", "P1", "LP1", "IC", "Cálculo.2", "Discreta", "P2", "LP2", "Grafos", "Física.3")

dados_treino = dados_treino[,2:15]
dados_validacao = dados_validacao[,2:15]

head(dados_treino)
```

Percebemos que algumas notas de disciplinas estão com valores vazios. Para que não precisemos remover toda a linha do data frame, vamos realizar imputação de dados. Decidimos que os valores vazios em disciplinas serão substituídos pelo valor do cra de suas respectivas matrículas.

```{r}
for(i in 1:nrow(dados_treino)){
  for(j in 1:ncol(dados_treino)){
    if(is.na(dados_treino[i,j])){
      dados_treino[i, j] = dados_treino$cra[i]
    }
    if(i <= nrow(dados_validacao)){
      if(is.na(dados_validacao[i,j])){
        dados_validacao[i, j] = dados_validacao$cra[i]
      }
    }
  }
}

head(dados_treino)
```

Como resultado final e para uma apresentação dos dados antes a criação de modelos, podemos ver abaixo a tabela de correlação entre a variáveis.

```{r, fig.width=9, fig.height=7}
M = cor(na.omit(dados_treino[,2:14]))

corrplot(M, type = "lower", title = "Correlação de disciplinas",  order="hclust", col=brewer.pal(n=7, name="PuOr"), addCoef.col = "black", tl.col="black", tl.srt=45, mar=c(0,0,1,0) )
```

## Modelo de regressão Ridge

Iniciaremos utilizando o método de regularização Ridge Regression, que suaviza atributos relacionados e que aumentam o ruído no modelo. Porque queremos encontrar o bom valor lambda para o modelo, utilizamos nos dados de treino a função *train* para escolher aquele com menor RMSE dentre 100 possíveis valores lambda.

```{r warning=FALSE, message=FALSE}
set.seed(825)
fitControl <- trainControl(method = "cv",
                           number = 10)

lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=100))

ridge <- train(cra~., data = dados_treino[,2:14],
               method='ridge',
               trControl = fitControl,
                tuneGrid = lambdaGrid,
               preProcess=c('center', 'scale')
)
```

Abaixo vemos a sequência de valores obtidos e uma representação gráfica do mesmo. 

```{r warning=FALSE, message=FALSE}
ridge
plot(ridge)
```

Em seguida, realizamos a predição dos dados, mas agora utilizando os dados de validação. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos. 

```{r}
ridge.pred <- predict(ridge, dados_validacao[,2:14])

ridge.pred <- data.frame(pred = ridge.pred, obs = dados_validacao$cra)

ggplot(ridge.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
```

O RMSE alto indica que o erro na predição foi alto. Ao utlizar a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.449. 

```{r}
round(defaultSummary(ridge.pred), digits = 3)
```

## Modelo de regressão Lasso

Assim como no tópico anterior, criaremos um novo modelo agora utilizando o método Lasso para a seleção de preditores. Após a criação e treinamento do modelo, também realizaremos a predição do mesmo. 

```{r}
lasso <- train(cra~., data = dados_treino[,2:14],
               method='lasso',
                tuneLength = 10,
               preProcess=c('center', 'scale')
)
```

O gráfico abaixo ilustra os 10 valores obtidos para fraction e a relação com seus respectivos RMSE. Em seguida os mesmos valores em detalhes.

```{r}
plot(lasso)
lasso
```

Para realizar a predição dos dados também utilizamos os dados de validação. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos.

```{r}
lasso.pred <- predict(lasso, dados_validacao[,2:14])

lasso.pred <- data.frame(pred = lasso.pred, obs = dados_validacao$cra)

ggplot(lasso.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
```

Utilizando a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.437. 

```{r}
round(defaultSummary(lasso.pred), digits = 3)
```

## Comparação de modelos

Realizamos a comparação de modelos com base nos valores obtidos no RMSE. Quanto mais baixo o valor, melhor. Abaixo temos os gráficos mostrados anteriormente, agora lado a lado para uma melhor comparação.Vemos que o comportamento nos dados de validação é bem semelhante, os gráficos gerados não apresentam uma diferença perceptível muito significante.

```{r}
compare <- ridge.pred
compare$model <- "Ridge"
lasso.pred$model <- "Lasso"

compare <- rbind(compare, lasso.pred)

ggplot(compare, aes(x = pred, y = obs)) + 
  geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + 
  facet_grid(. ~ model) + 
  geom_abline() +
  ggtitle("Observado x Previsão (validação)")
```

Assim como nos gráficos, o fenômeno se repetiu para os valores de RSME. Ambos são altos e com quase o mesmo valor. Porém, o RMSE do modelo Lasso consegue atingir um menor valor. Podemos então considerar que o melhor modelo é o que utiliza da técnica Lasso. O melhor modelo é aquele que possui o RMSE mais baixo. 

```{r}
round(defaultSummary(ridge.pred), digits = 3)
round(defaultSummary(lasso.pred), digits = 3)
```

## Importância de variáveis no modelo Lasso

Geramos uma representação gráfica com a importância das variáveis e mais abaixo estão os valores detalhados sobre a importância das mesmas. Vemos que Cálculo 2 é apresentada como a variável de maior importância, seguida por IC e P2. Temos apenas uma variável discartada que foi Física 3, apresentando overall igual a 0. 

```{r}
plot(varImp(lasso))
varImp(lasso)
```

## Re-treino de modelo Lasso com dados de validação

Repetiremos aqui os passos realizados na construção e treino do modelo Lasso. Porém, desta vez estaremos utilizando os dados de validação para treinar o modelo. Segue:

```{r}
lasso <- train(cra~., data = dados_validacao[,2:14],
               method='lasso',
                tuneLength = 10,
               preProcess=c('center', 'scale'))
```

O gráfico abaixo ilustra os 10 valores obtidos para fraction e a relação com seus respectivos RMSE. Em seguida os mesmos valores em detalhes.

```{r}
plot(lasso)
lasso
```

Em seguida, a realização de predição utilizando os mesmos dados. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos.

```{r}
lasso.pred <- predict(lasso, dados_validacao[,2:14])

lasso.pred <- data.frame(pred = lasso.pred, obs = dados_validacao$cra)

ggplot(lasso.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
```

Utilizando a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.454. Ao interpretar o resultado da função entendemos que houve um aumento no valor do RMSE e, consequentemente, uma piora no modelo.

```{r}
round(defaultSummary(lasso.pred), digits = 3)
```

## Tentativa de melhora no modelo

Para tentar melhorar o modelo, vamos tentar uma nova abordagem para imputação de dados. Inicialmente, fazíamos a substituição de valores NA pelo valor do cra. Agora substituiremos esses valores vazios pela média das notas do primeiro período.

```{r}
dados_treino = read.csv("p1p2.graduados_treino.csv")
dados_validacao = read.csv("p1p2.graduados_validacao.csv")

dados_treino = dados_treino[,2:15]
dados_validacao = dados_validacao[,2:15]

for(i in 1:nrow(dados_treino)){
  for(j in 1:ncol(dados_treino)){
    if(is.na(dados_treino[i,j])){
      dados_treino[i, j] = rowMeans(dados_treino[i,2:13], na.rm = T)
    }
    if(i <= nrow(dados_validacao)){
      if(is.na(dados_validacao[i,j])){
        dados_validacao[i, j] = rowMeans(dados_treino[i,2:13], na.rm = T)
      }
    }
  }
}
```

Assim como nos tópicos anteriores, criamos o modelo utlizando os dados de treino.

```{r}
lasso <- train(cra~., data = dados_treino[,2:14],
               method='lasso',
                tuneLength = 10,
               preProcess=c('center', 'scale'))
```

O gráfico abaixo ilustra os 10 valores obtidos para fraction e a relação com seus respectivos RMSE. Em seguida os mesmos valores em detalhes.

```{r}
plot(lasso)
lasso
```

Em seguida, a realização de predição utilizando os dados de validação. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos.

```{r}
lasso.pred <- predict(lasso, dados_validacao[,2:14])

lasso.pred <- data.frame(pred = lasso.pred, obs = dados_validacao$cra)

ggplot(lasso.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
```

Geramos uma representação gráfica com a importância das variáveis e mais abaixo estão os valores detalhados sobre a importância das mesmas. Vemos que Cálculo 2 continua sendo apresentada como a variável de maior importância, seguida por IC e agora Grafos. Temos apenas uma variável discartada que para o novo modelo foi LPT, apresentando overall igual a 0. 

```{r}
plot(varImp(lasso))
varImp(lasso)
```

Utilizando a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.411. Ao interpretar o resultado da função entendemos que houve uma diminuição no valor do RMSE e, consequentemente, uma melhora no modelo.

```{r}
round(defaultSummary(lasso.pred), digits = 3)
```

## Gerando dados de predição

Para gerar dados de predição utilizamos dados de teste. Realizamos a predição de cra a partir das disciplinas dos dois primeiros semestres. O resultado foi submetido na plataforma Kaggle.

```{r}
head(dados_teste)
dados_teste$cra = NA
dados_teste$cra = predict(lasso, dados_teste)
dados_teste = dados_teste[,c("matricula","cra")]
head(dados_teste)
```
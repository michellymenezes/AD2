---
layout: post
title: Uso de modelos de regressão com Ridge e Lasso
date: "2018-04-06 21:42:44"
published: true
tags: [example1, example2]
---




## Apresentação dos dados

Como continuação da Parte 2, nesse fase estaremos criando modelos de regressão, comparando-os e realizando predição de dados. Continuamos trabalhando com disciplinas dos dois primeiros semestres para a criação de um modelo que consiga calcular o cra de uma determinada matrícula. Para isso dividimos os dados em treino, validação e teste. 

*Legenda*

* ***Cálculo.1***: Cálculo Diferencial e Integral I - Período 1
* ***Vetorial***: Álgebra Vetorial e Geometria Analítica - Período 1
* ***LPT***: Leitura e Produção de Textos - Período 1
* ***P1***: Programação I - Período 1
* ***LP1***: Laboratório de Programação I - Período 1
* ***IC***: Introdução à Computação - Período 1
* ***Cálculo.2***: Cálculo Diferencial e Integral II - Período 2
* ***Discreta***: Matemática Discreta - Período 2
* ***P2***: Programação II - Período 2
* ***LP2***: Laboratório de Programação II - Período 2
* ***Grafos***: Teoria dos Grafos - Período 2
* ***Física.3***: Fundamentos de Física Clássica - Período 2


{% highlight r %}
dados_treino = read.csv("p1p2.graduados_treino.csv")
dados_validacao = read.csv("p1p2.graduados_validacao.csv")
dados_teste = read.csv("test.csv")

colnames(dados_teste) = c("matricula", "Cálculo.1", "Vetorial", "LPT", "P1", "LP1", "IC", "Cálculo.2", "Discreta", "P2", "LP2", "Grafos", "Física.3")

dados_treino = dados_treino[,2:15]
dados_validacao = dados_validacao[,2:15]

head(dados_treino)
{% endhighlight %}



{% highlight text %}
##                          Matricula Cálculo.1 Vetorial LPT  P1 LP1  IC
## 1 002b348d3bc88b68aa6ebd24cfc9d6a0       5.6      7.5 9.1 8.0 8.7 8.4
## 2 007961bf3929ae353c8585e6c09df369       6.7      8.5 8.6 7.1 7.6 7.7
## 3 00960ff73dd29b59f4432072c2219c04       7.0      5.6 6.5 7.3 8.5 7.5
## 4 00b6f55e3639c9d3b835751a39ca6309        NA      7.3  NA  NA  NA  NA
## 5 00eb58fa89c562efda118e64efab77a5       5.5      7.0 7.4 6.8 6.3 8.6
## 6 01fc383ae2c2cb3e69d844272a5ecac0       6.6      5.9 8.3 9.1 8.8 9.5
##   Cálculo.2 Discreta  P2 LP2 Grafos Física.3      cra
## 1        NA      9.2 7.7 8.6    7.2      9.6 8.109877
## 2        NA      5.0 5.7 8.0    7.0      7.8 6.975824
## 3        NA      5.3 5.6 8.1    7.9      7.0 6.057282
## 4       7.2       NA  NA  NA     NA       NA 7.766667
## 5        NA      6.7 7.9 9.0    6.1      7.1 7.693827
## 6        NA      6.1 6.8 9.0    5.3      7.3 6.722892
{% endhighlight %}

Percebemos que algumas notas de disciplinas estão com valores vazios. Para que não precisemos remover toda a linha do data frame, vamos realizar imputação de dados. Decidimos que os valores vazios em disciplinas serão substituídos pelo valor do cra de suas respectivas matrículas.


{% highlight r %}
for(i in 1:nrow(dados_treino)){
  for(j in 1:ncol(dados_treino)){
    if(is.na(dados_treino[i,j])){
      dados_treino[i, j] = dados_treino$cra[i]
    }
    if(i <= nrow(dados_validacao)){
      if(is.na(dados_validacao[i,j])){
        dados_validacao[i, j] = dados_validacao$cra[i]
      }
    }
  }
}

head(dados_treino)
{% endhighlight %}



{% highlight text %}
##                          Matricula Cálculo.1 Vetorial      LPT
## 1 002b348d3bc88b68aa6ebd24cfc9d6a0  5.600000      7.5 9.100000
## 2 007961bf3929ae353c8585e6c09df369  6.700000      8.5 8.600000
## 3 00960ff73dd29b59f4432072c2219c04  7.000000      5.6 6.500000
## 4 00b6f55e3639c9d3b835751a39ca6309  7.766667      7.3 7.766667
## 5 00eb58fa89c562efda118e64efab77a5  5.500000      7.0 7.400000
## 6 01fc383ae2c2cb3e69d844272a5ecac0  6.600000      5.9 8.300000
##         P1      LP1       IC Cálculo.2 Discreta       P2      LP2
## 1 8.000000 8.700000 8.400000  8.109877 9.200000 7.700000 8.600000
## 2 7.100000 7.600000 7.700000  6.975824 5.000000 5.700000 8.000000
## 3 7.300000 8.500000 7.500000  6.057282 5.300000 5.600000 8.100000
## 4 7.766667 7.766667 7.766667  7.200000 7.766667 7.766667 7.766667
## 5 6.800000 6.300000 8.600000  7.693827 6.700000 7.900000 9.000000
## 6 9.100000 8.800000 9.500000  6.722892 6.100000 6.800000 9.000000
##     Grafos Física.3      cra
## 1 7.200000 9.600000 8.109877
## 2 7.000000 7.800000 6.975824
## 3 7.900000 7.000000 6.057282
## 4 7.766667 7.766667 7.766667
## 5 6.100000 7.100000 7.693827
## 6 5.300000 7.300000 6.722892
{% endhighlight %}

Como resultado final e para uma apresentação dos dados antes a criação de modelos, podemos ver abaixo a tabela de correlação entre a variáveis.


{% highlight r %}
M = cor(na.omit(dados_treino[,2:14]))

corrplot(M, type = "lower", title = "Correlação de disciplinas",  order="hclust", col=brewer.pal(n=7, name="PuOr"), addCoef.col = "black", tl.col="black", tl.srt=45, mar=c(0,0,1,0) )
{% endhighlight %}

![plot of chunk unnamed-chunk-3](/AD2/Figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-3-1.png)

## Modelo de regressão Ridge

Iniciaremos utilizando o método de regularização Ridge Regression, que suaviza atributos relacionados e que aumentam o ruído no modelo. Porque queremos encontrar o bom valor lambda para o modelo, utilizamos nos dados de treino a função *train* para escolher aquele com menor RMSE dentre 100 possíveis valores lambda.


{% highlight r %}
set.seed(825)
fitControl <- trainControl(method = "cv",
                           number = 10)

lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=100))

ridge <- train(cra~., data = dados_treino[,2:14],
               method='ridge',
               trControl = fitControl,
                tuneGrid = lambdaGrid,
               preProcess=c('center', 'scale')
)
{% endhighlight %}



{% highlight text %}
## 1 package is needed for this model and is not installed. (elasticnet). Would you like to try to install it now?
{% endhighlight %}



{% highlight text %}
## Error: Required package is missing
{% endhighlight %}

Abaixo vemos a sequência de valores obtidos e uma representação gráfica do mesmo. 


{% highlight r %}
ridge
{% endhighlight %}



{% highlight text %}
## Error in eval(expr, envir, enclos): objeto 'ridge' não encontrado
{% endhighlight %}



{% highlight r %}
plot(ridge)
{% endhighlight %}



{% highlight text %}
## Error in plot(ridge): objeto 'ridge' não encontrado
{% endhighlight %}

Em seguida, realizamos a predição dos dados, mas agora utilizando os dados de validação. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos. 


{% highlight r %}
ridge.pred <- predict(ridge, dados_validacao[,2:14])
{% endhighlight %}



{% highlight text %}
## Error in predict(ridge, dados_validacao[, 2:14]): objeto 'ridge' não encontrado
{% endhighlight %}



{% highlight r %}
ridge.pred <- data.frame(pred = ridge.pred, obs = dados_validacao$cra)
{% endhighlight %}



{% highlight text %}
## Error in data.frame(pred = ridge.pred, obs = dados_validacao$cra): objeto 'ridge.pred' não encontrado
{% endhighlight %}



{% highlight r %}
ggplot(ridge.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
{% endhighlight %}



{% highlight text %}
## Error in ggplot(ridge.pred, aes(x = pred, y = obs)): objeto 'ridge.pred' não encontrado
{% endhighlight %}

O RMSE alto indica que o erro na predição foi alto. Ao utlizar a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.449. 


{% highlight r %}
round(defaultSummary(ridge.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
## Error in defaultSummary(ridge.pred): objeto 'ridge.pred' não encontrado
{% endhighlight %}

## Modelo de regressão Lasso

Assim como no tópico anterior, criaremos um novo modelo agora utilizando o método Lasso para a seleção de preditores. Após a criação e treinamento do modelo, também realizaremos a predição do mesmo. 


{% highlight r %}
lasso <- train(cra~., data = dados_treino[,2:14],
               method='lasso',
                tuneLength = 10,
               preProcess=c('center', 'scale')
)
{% endhighlight %}



{% highlight text %}
## 1 package is needed for this model and is not installed. (elasticnet). Would you like to try to install it now?
{% endhighlight %}



{% highlight text %}
## Error: Required package is missing
{% endhighlight %}

O gráfico abaixo ilustra os 10 valores obtidos para fraction e a relação com seus respectivos RMSE. Em seguida os mesmos valores em detalhes.


{% highlight r %}
plot(lasso)
{% endhighlight %}



{% highlight text %}
## Error in plot(lasso): objeto 'lasso' não encontrado
{% endhighlight %}



{% highlight r %}
lasso
{% endhighlight %}



{% highlight text %}
## Error in eval(expr, envir, enclos): objeto 'lasso' não encontrado
{% endhighlight %}

Para realizar a predição dos dados também utilizamos os dados de validação. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos.


{% highlight r %}
lasso.pred <- predict(lasso, dados_validacao[,2:14])
{% endhighlight %}



{% highlight text %}
## Error in predict(lasso, dados_validacao[, 2:14]): objeto 'lasso' não encontrado
{% endhighlight %}



{% highlight r %}
lasso.pred <- data.frame(pred = lasso.pred, obs = dados_validacao$cra)
{% endhighlight %}



{% highlight text %}
## Error in data.frame(pred = lasso.pred, obs = dados_validacao$cra): objeto 'lasso.pred' não encontrado
{% endhighlight %}



{% highlight r %}
ggplot(lasso.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
{% endhighlight %}



{% highlight text %}
## Error in ggplot(lasso.pred, aes(x = pred, y = obs)): objeto 'lasso.pred' não encontrado
{% endhighlight %}

Utilizando a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.437. 


{% highlight r %}
round(defaultSummary(lasso.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
## Error in defaultSummary(lasso.pred): objeto 'lasso.pred' não encontrado
{% endhighlight %}

## Comparação de modelos

Realizamos a comparação de modelos com base nos valores obtidos no RMSE. Quanto mais baixo o valor, melhor. Abaixo temos os gráficos mostrados anteriormente, agora lado a lado para uma melhor comparação.Vemos que o comportamento nos dados de validação é bem semelhante, os gráficos gerados não apresentam uma diferença perceptível muito significante.


{% highlight r %}
compare <- ridge.pred
{% endhighlight %}



{% highlight text %}
## Error in eval(expr, envir, enclos): objeto 'ridge.pred' não encontrado
{% endhighlight %}



{% highlight r %}
compare$model <- "Ridge"
{% endhighlight %}



{% highlight text %}
## Error in compare$model <- "Ridge": objeto 'compare' não encontrado
{% endhighlight %}



{% highlight r %}
lasso.pred$model <- "Lasso"
{% endhighlight %}



{% highlight text %}
## Error in lasso.pred$model <- "Lasso": objeto 'lasso.pred' não encontrado
{% endhighlight %}



{% highlight r %}
compare <- rbind(compare, lasso.pred)
{% endhighlight %}



{% highlight text %}
## Error in rbind(compare, lasso.pred): objeto 'compare' não encontrado
{% endhighlight %}



{% highlight r %}
ggplot(compare, aes(x = pred, y = obs)) + 
  geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + 
  facet_grid(. ~ model) + 
  geom_abline() +
  ggtitle("Observado x Previsão (validação)")
{% endhighlight %}



{% highlight text %}
## Error in ggplot(compare, aes(x = pred, y = obs)): objeto 'compare' não encontrado
{% endhighlight %}

Assim como nos gráficos, o fenômeno se repetiu para os valores de RSME. Ambos são altos e com quase o mesmo valor. Porém, o RMSE do modelo Lasso consegue atingir um menor valor. Podemos então considerar que o melhor modelo é o que utiliza da técnica Lasso. O melhor modelo é aquele que possui o RMSE mais baixo. 


{% highlight r %}
round(defaultSummary(ridge.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
## Error in defaultSummary(ridge.pred): objeto 'ridge.pred' não encontrado
{% endhighlight %}



{% highlight r %}
round(defaultSummary(lasso.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
## Error in defaultSummary(lasso.pred): objeto 'lasso.pred' não encontrado
{% endhighlight %}

## Importância de variáveis no modelo Lasso

Geramos uma representação gráfica com a importância das variáveis e mais abaixo estão os valores detalhados sobre a importância das mesmas. Vemos que Cálculo 2 é apresentada como a variável de maior importância, seguida por IC e P2. Temos apenas uma variável discartada que foi Física 3, apresentando overall igual a 0. 


{% highlight r %}
plot(varImp(lasso))
{% endhighlight %}



{% highlight text %}
## Error in varImp(lasso): objeto 'lasso' não encontrado
{% endhighlight %}



{% highlight r %}
varImp(lasso)
{% endhighlight %}



{% highlight text %}
## Error in varImp(lasso): objeto 'lasso' não encontrado
{% endhighlight %}

## Re-treino de modelo Lasso com dados de validação

Repetiremos aqui os passos realizados na construção e treino do modelo Lasso. Porém, desta vez estaremos utilizando os dados de validação para treinar o modelo. Segue:


{% highlight r %}
lasso <- train(cra~., data = dados_validacao[,2:14],
               method='lasso',
                tuneLength = 10,
               preProcess=c('center', 'scale'))
{% endhighlight %}



{% highlight text %}
## 1 package is needed for this model and is not installed. (elasticnet). Would you like to try to install it now?
{% endhighlight %}



{% highlight text %}
## Error: Required package is missing
{% endhighlight %}

O gráfico abaixo ilustra os 10 valores obtidos para fraction e a relação com seus respectivos RMSE. Em seguida os mesmos valores em detalhes.


{% highlight r %}
plot(lasso)
{% endhighlight %}



{% highlight text %}
## Error in plot(lasso): objeto 'lasso' não encontrado
{% endhighlight %}



{% highlight r %}
lasso
{% endhighlight %}



{% highlight text %}
## Error in eval(expr, envir, enclos): objeto 'lasso' não encontrado
{% endhighlight %}

Em seguida, a realização de predição utilizando os mesmos dados. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos.


{% highlight r %}
lasso.pred <- predict(lasso, dados_validacao[,2:14])
{% endhighlight %}



{% highlight text %}
## Error in predict(lasso, dados_validacao[, 2:14]): objeto 'lasso' não encontrado
{% endhighlight %}



{% highlight r %}
lasso.pred <- data.frame(pred = lasso.pred, obs = dados_validacao$cra)
{% endhighlight %}



{% highlight text %}
## Error in data.frame(pred = lasso.pred, obs = dados_validacao$cra): objeto 'lasso.pred' não encontrado
{% endhighlight %}



{% highlight r %}
ggplot(lasso.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
{% endhighlight %}



{% highlight text %}
## Error in ggplot(lasso.pred, aes(x = pred, y = obs)): objeto 'lasso.pred' não encontrado
{% endhighlight %}

Utilizando a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.454. Ao interpretar o resultado da função entendemos que houve um aumento no valor do RMSE e, consequentemente, uma piora no modelo.


{% highlight r %}
round(defaultSummary(lasso.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
## Error in defaultSummary(lasso.pred): objeto 'lasso.pred' não encontrado
{% endhighlight %}

## Tentativa de melhora no modelo

Para tentar melhorar o modelo, vamos tentar uma nova abordagem para imputação de dados. Inicialmente, fazíamos a substituição de valores NA pelo valor do cra. Agora substituiremos esses valores vazios pela média das notas do primeiro período.


{% highlight r %}
dados_treino = read.csv("p1p2.graduados_treino.csv")
dados_validacao = read.csv("p1p2.graduados_validacao.csv")

dados_treino = dados_treino[,2:15]
dados_validacao = dados_validacao[,2:15]

for(i in 1:nrow(dados_treino)){
  for(j in 1:ncol(dados_treino)){
    if(is.na(dados_treino[i,j])){
      dados_treino[i, j] = rowMeans(dados_treino[i,2:13], na.rm = T)
    }
    if(i <= nrow(dados_validacao)){
      if(is.na(dados_validacao[i,j])){
        dados_validacao[i, j] = rowMeans(dados_treino[i,2:13], na.rm = T)
      }
    }
  }
}
{% endhighlight %}

Assim como nos tópicos anteriores, criamos o modelo utlizando os dados de treino.


{% highlight r %}
lasso <- train(cra~., data = dados_treino[,2:14],
               method='lasso',
                tuneLength = 10,
               preProcess=c('center', 'scale'))
{% endhighlight %}



{% highlight text %}
## 1 package is needed for this model and is not installed. (elasticnet). Would you like to try to install it now?
{% endhighlight %}



{% highlight text %}
## Error: Required package is missing
{% endhighlight %}

O gráfico abaixo ilustra os 10 valores obtidos para fraction e a relação com seus respectivos RMSE. Em seguida os mesmos valores em detalhes.


{% highlight r %}
plot(lasso)
{% endhighlight %}



{% highlight text %}
## Error in plot(lasso): objeto 'lasso' não encontrado
{% endhighlight %}



{% highlight r %}
lasso
{% endhighlight %}



{% highlight text %}
## Error in eval(expr, envir, enclos): objeto 'lasso' não encontrado
{% endhighlight %}

Em seguida, a realização de predição utilizando os dados de validação. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos.


{% highlight r %}
lasso.pred <- predict(lasso, dados_validacao[,2:14])
{% endhighlight %}



{% highlight text %}
## Error in predict(lasso, dados_validacao[, 2:14]): objeto 'lasso' não encontrado
{% endhighlight %}



{% highlight r %}
lasso.pred <- data.frame(pred = lasso.pred, obs = dados_validacao$cra)
{% endhighlight %}



{% highlight text %}
## Error in data.frame(pred = lasso.pred, obs = dados_validacao$cra): objeto 'lasso.pred' não encontrado
{% endhighlight %}



{% highlight r %}
ggplot(lasso.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
{% endhighlight %}



{% highlight text %}
## Error in ggplot(lasso.pred, aes(x = pred, y = obs)): objeto 'lasso.pred' não encontrado
{% endhighlight %}

Geramos uma representação gráfica com a importância das variáveis e mais abaixo estão os valores detalhados sobre a importância das mesmas. Vemos que Cálculo 2 continua sendo apresentada como a variável de maior importância, seguida por IC e agora Grafos. Temos apenas uma variável discartada que para o novo modelo foi LPT, apresentando overall igual a 0. 


{% highlight r %}
plot(varImp(lasso))
{% endhighlight %}



{% highlight text %}
## Error in varImp(lasso): objeto 'lasso' não encontrado
{% endhighlight %}



{% highlight r %}
varImp(lasso)
{% endhighlight %}



{% highlight text %}
## Error in varImp(lasso): objeto 'lasso' não encontrado
{% endhighlight %}

Utilizando a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.411. Ao interpretar o resultado da função entendemos que houve uma diminuição no valor do RMSE e, consequentemente, uma melhora no modelo.


{% highlight r %}
round(defaultSummary(lasso.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
## Error in defaultSummary(lasso.pred): objeto 'lasso.pred' não encontrado
{% endhighlight %}

## Gerando dados de predição

Para gerar dados de predição utilizamos dados de teste. Realizamos a predição de cra a partir das disciplinas dos dois primeiros semestres. O resultado foi submetido na plataforma Kaggle.


{% highlight r %}
head(dados_teste)
{% endhighlight %}



{% highlight text %}
##                          matricula Cálculo.1 Vetorial LPT  P1  LP1
## 1 037119c4740aa04d14742993e4aab789       8.2      9.1 8.3 7.0 10.0
## 2 0402a824ba0c87f73209cdb49b5072be       5.0      7.7 7.8 8.8  7.1
## 3 075d778a8444ef224757557479320148       5.2      5.0 9.6 7.8  6.2
## 4 09b9a1b335be033c236add2ba699c13f       7.6      6.0 8.7 7.0  8.4
## 5 0d3c0ddcdd2a97627575c27b5d1a058a       8.3      8.1 7.0 8.4  9.4
## 6 107f352e7c2d881c0f5f72a4584cd8fd       5.5      6.9 7.3 7.0  9.1
##    IC Cálculo.2 Discreta  P2 LP2 Grafos Física.3
## 1 7.7       9.2      9.7 9.2 8.9    9.1      9.0
## 2 8.8       7.3      7.3 7.1 7.3    8.0      6.0
## 3 5.4       5.1      5.0 5.7 7.0    7.0      9.3
## 4 7.0       5.0      5.9 7.8 6.0    6.6      5.9
## 5 8.4       7.8      7.9 8.5 8.5    8.0      8.0
## 6 7.4       7.0      7.6 9.4 5.2    8.4      8.8
{% endhighlight %}



{% highlight r %}
dados_teste$cra = NA
dados_teste$cra = predict(lasso, dados_teste)
{% endhighlight %}



{% highlight text %}
## Error in predict(lasso, dados_teste): objeto 'lasso' não encontrado
{% endhighlight %}



{% highlight r %}
dados_teste = dados_teste[,c("matricula","cra")]
head(dados_teste)
{% endhighlight %}



{% highlight text %}
##                          matricula cra
## 1 037119c4740aa04d14742993e4aab789  NA
## 2 0402a824ba0c87f73209cdb49b5072be  NA
## 3 075d778a8444ef224757557479320148  NA
## 4 09b9a1b335be033c236add2ba699c13f  NA
## 5 0d3c0ddcdd2a97627575c27b5d1a058a  NA
## 6 107f352e7c2d881c0f5f72a4584cd8fd  NA
{% endhighlight %}

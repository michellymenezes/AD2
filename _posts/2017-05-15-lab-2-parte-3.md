---
layout: post
title:  Laboratório 2 - Parte 3
date: "2017-05-15 15:07:52"
published: true
tags: [example1, example2]
---




## Apresentação dos dados

Como continuação da Parte 2, nesse fase estaremos criando modelos de regressão, comparando-os e realizando predição de dados. Continuamos trabalhando com disciplinas dos dois primeiros semestres para a criação de um modelo que consiga calcular o cra de uma determinada matrícula. Para isso dividimos os dados em treino, validação e teste. 

*Legenda*

* ***Cálculo.1***: Cálculo Diferencial e Integral I - Período 1
* ***Vetorial***: Álgebra Vetorial e Geometria Analítica - Período 1
* ***LPT***: Leitura e Produção de Textos - Período 1
* ***P1***: Programação I - Período 1
* ***LP1***: Laboratório de Programação I - Período 1
* ***IC***: Introdução à Computação - Período 1
* ***Cálculo.2***: Cálculo Diferencial e Integral II - Período 2
* ***Discreta***: Matemática Discreta - Período 2
* ***P2***: Programação II - Período 2
* ***LP2***: Laboratório de Programação II - Período 2
* ***Grafos***: Teoria dos Grafos - Período 2
* ***Física.3***: Fundamentos de Física Clássica - Período 2


{% highlight r %}
dados_treino = read.csv("p1p2.graduados_treino.csv")
dados_validacao = read.csv("p1p2.graduados_validacao.csv")
dados_teste = read.csv("test.csv")

colnames(dados_teste) = c("matricula", "Cálculo.1", "Vetorial", "LPT", "P1", "LP1", "IC", "Cálculo.2", "Discreta", "P2", "LP2", "Grafos", "Física.3")

dados_treino = dados_treino[,2:15]
dados_validacao = dados_validacao[,2:15]

head(dados_treino)
{% endhighlight %}



{% highlight text %}
##                          Matricula Cálculo.1 Vetorial LPT  P1 LP1  IC
## 1 002b348d3bc88b68aa6ebd24cfc9d6a0       5.6      7.5 9.1 8.0 8.7 8.4
## 2 007961bf3929ae353c8585e6c09df369       6.7      8.5 8.6 7.1 7.6 7.7
## 3 00960ff73dd29b59f4432072c2219c04       7.0      5.6 6.5 7.3 8.5 7.5
## 4 00b6f55e3639c9d3b835751a39ca6309        NA      7.3  NA  NA  NA  NA
## 5 00eb58fa89c562efda118e64efab77a5       5.5      7.0 7.4 6.8 6.3 8.6
## 6 01fc383ae2c2cb3e69d844272a5ecac0       6.6      5.9 8.3 9.1 8.8 9.5
##   Cálculo.2 Discreta  P2 LP2 Grafos Física.3      cra
## 1        NA      9.2 7.7 8.6    7.2      9.6 8.109877
## 2        NA      5.0 5.7 8.0    7.0      7.8 6.975824
## 3        NA      5.3 5.6 8.1    7.9      7.0 6.057282
## 4       7.2       NA  NA  NA     NA       NA 7.766667
## 5        NA      6.7 7.9 9.0    6.1      7.1 7.693827
## 6        NA      6.1 6.8 9.0    5.3      7.3 6.722892
{% endhighlight %}

Percebemos que algumas notas de disciplinas estão com valores vazios. Para que não precisemos remover toda a linha do data frame, vamos realizar imputação de dados. Decidimos que os valores vazios em disciplinas serão substituídos pelo valor do cra de suas respectivas matrículas.


{% highlight r %}
for(i in 1:nrow(dados_treino)){
  for(j in 1:ncol(dados_treino)){
    if(is.na(dados_treino[i,j])){
      dados_treino[i, j] = dados_treino$cra[i]
    }
    if(i <= nrow(dados_validacao)){
      if(is.na(dados_validacao[i,j])){
        dados_validacao[i, j] = dados_validacao$cra[i]
      }
    }
  }
}

head(dados_treino)
{% endhighlight %}



{% highlight text %}
##                          Matricula Cálculo.1 Vetorial      LPT
## 1 002b348d3bc88b68aa6ebd24cfc9d6a0  5.600000      7.5 9.100000
## 2 007961bf3929ae353c8585e6c09df369  6.700000      8.5 8.600000
## 3 00960ff73dd29b59f4432072c2219c04  7.000000      5.6 6.500000
## 4 00b6f55e3639c9d3b835751a39ca6309  7.766667      7.3 7.766667
## 5 00eb58fa89c562efda118e64efab77a5  5.500000      7.0 7.400000
## 6 01fc383ae2c2cb3e69d844272a5ecac0  6.600000      5.9 8.300000
##         P1      LP1       IC Cálculo.2 Discreta       P2      LP2
## 1 8.000000 8.700000 8.400000  8.109877 9.200000 7.700000 8.600000
## 2 7.100000 7.600000 7.700000  6.975824 5.000000 5.700000 8.000000
## 3 7.300000 8.500000 7.500000  6.057282 5.300000 5.600000 8.100000
## 4 7.766667 7.766667 7.766667  7.200000 7.766667 7.766667 7.766667
## 5 6.800000 6.300000 8.600000  7.693827 6.700000 7.900000 9.000000
## 6 9.100000 8.800000 9.500000  6.722892 6.100000 6.800000 9.000000
##     Grafos Física.3      cra
## 1 7.200000 9.600000 8.109877
## 2 7.000000 7.800000 6.975824
## 3 7.900000 7.000000 6.057282
## 4 7.766667 7.766667 7.766667
## 5 6.100000 7.100000 7.693827
## 6 5.300000 7.300000 6.722892
{% endhighlight %}

Como resultado final e para uma apresentação dos dados antes a criação de modelos, podemos ver abaixo a tabela de correlação entre a variáveis.


{% highlight r %}
M = cor(na.omit(dados_treino[,2:14]))

corrplot(M, type = "lower", title = "Correlação de disciplinas",  order="hclust", col=brewer.pal(n=7, name="PuOr"), addCoef.col = "black", tl.col="black", tl.srt=45, mar=c(0,0,1,0) )
{% endhighlight %}

![plot of chunk unnamed-chunk-3](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-3-1.png)

## Modelo de regressão Ridge

Iniciaremos utilizando o método de regularização Ridge Regression, que suaviza atributos relacionados e que aumentam o ruído no modelo. Porque queremos encontrar o bom valor lambda para o modelo, utilizamos nos dados de treino a função *train* para escolher aquele com menor RMSE dentre 100 possíveis valores lambda.


{% highlight r %}
set.seed(825)
fitControl <- trainControl(method = "cv",
                           number = 10)

lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=100))

ridge <- train(cra~., data = dados_treino[,2:14],
               method='ridge',
               trControl = fitControl,
                tuneGrid = lambdaGrid,
               preProcess=c('center', 'scale')
)
{% endhighlight %}

Abaixo vemos a sequência de valores obtidos e uma representação gráfica do mesmo. 


{% highlight r %}
ridge
{% endhighlight %}



{% highlight text %}
## Ridge Regression 
## 
## 511 samples
##  12 predictor
## 
## Pre-processing: centered (12), scaled (12) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 459, 459, 459, 461, 460, 461, ... 
## Resampling results across tuning parameters:
## 
##   lambda        RMSE       Rsquared 
##   1.000000e-02  0.4702298  0.7088850
##   1.321941e-02  0.4702420  0.7089405
##   1.747528e-02  0.4702705  0.7090096
##   2.310130e-02  0.4703295  0.7090939
##   3.053856e-02  0.4704443  0.7091935
##   4.037017e-02  0.4706593  0.7093062
##   5.336699e-02  0.4710517  0.7094251
##   7.054802e-02  0.4717539  0.7095363
##   9.326033e-02  0.4729915  0.7096156
##   1.232847e-01  0.4751422  0.7096254
##   1.629751e-01  0.4788289  0.7095135
##   2.154435e-01  0.4850543  0.7092155
##   2.848036e-01  0.4953801  0.7086617
##   3.764936e-01  0.5121245  0.7077907
##   4.977024e-01  0.5384997  0.7065657
##   6.579332e-01  0.5785481  0.7049890
##   8.697490e-01  0.6367339  0.7031088
##   1.149757e+00  0.7171769  0.7010140
##   1.519911e+00  0.8227305  0.6988181
##   2.009233e+00  0.9541925  0.6966382
##   2.656088e+00  1.1098394  0.6945759
##   3.511192e+00  1.2853530  0.6927046
##   4.641589e+00  1.4741742  0.6910660
##   6.135907e+00  1.6682948  0.6896735
##   8.111308e+00  1.8593786  0.6885190
##   1.072267e+01  2.0399445  0.6875807
##   1.417474e+01  2.2042917  0.6868302
##   1.873817e+01  2.3489455  0.6862375
##   2.477076e+01  2.4726041  0.6857742
##   3.274549e+01  2.5757280  0.6854146
##   4.328761e+01  2.6599755  0.6851374
##   5.722368e+01  2.7276572  0.6849245
##   7.564633e+01  2.7813040  0.6847617
##   1.000000e+02  2.8233754  0.6846374
##   1.321941e+02  2.8560948  0.6845428
##   1.747528e+02  2.8813763  0.6844709
##   2.310130e+02  2.9008129  0.6844163
##   3.053856e+02  2.9156984  0.6843749
##   4.037017e+02  2.9270649  0.6843435
##   5.336699e+02  2.9357246  0.6843197
##   7.054802e+02  2.9423110  0.6843017
##   9.326033e+02  2.9473137  0.6842881
##   1.232847e+03  2.9511099  0.6842777
##   1.629751e+03  2.9539883  0.6842699
##   2.154435e+03  2.9561696  0.6842640
##   2.848036e+03  2.9578219  0.6842595
##   3.764936e+03  2.9590731  0.6842561
##   4.977024e+03  2.9600203  0.6842536
##   6.579332e+03  2.9607373  0.6842516
##   8.697490e+03  2.9612799  0.6842502
##   1.149757e+04  2.9616904  0.6842491
##   1.519911e+04  2.9620011  0.6842482
##   2.009233e+04  2.9622362  0.6842476
##   2.656088e+04  2.9624140  0.6842471
##   3.511192e+04  2.9625485  0.6842468
##   4.641589e+04  2.9626503  0.6842465
##   6.135907e+04  2.9627273  0.6842463
##   8.111308e+04  2.9627856  0.6842461
##   1.072267e+05  2.9628296  0.6842460
##   1.417474e+05  2.9628630  0.6842459
##   1.873817e+05  2.9628882  0.6842458
##   2.477076e+05  2.9629073  0.6842458
##   3.274549e+05  2.9629217  0.6842457
##   4.328761e+05  2.9629326  0.6842457
##   5.722368e+05  2.9629409  0.6842457
##   7.564633e+05  2.9629471  0.6842457
##   1.000000e+06  2.9629518  0.6842457
##   1.321941e+06  2.9629554  0.6842457
##   1.747528e+06  2.9629581  0.6842456
##   2.310130e+06  2.9629602  0.6842456
##   3.053856e+06  2.9629617  0.6842456
##   4.037017e+06  2.9629629  0.6842456
##   5.336699e+06  2.9629638  0.6842456
##   7.054802e+06  2.9629644  0.6842456
##   9.326033e+06  2.9629650  0.6842456
##   1.232847e+07  2.9629653  0.6842456
##   1.629751e+07  2.9629656  0.6842456
##   2.154435e+07  2.9629658  0.6842456
##   2.848036e+07  2.9629660  0.6842456
##   3.764936e+07  2.9629661  0.6842456
##   4.977024e+07  2.9629662  0.6842456
##   6.579332e+07  2.9629663  0.6842456
##   8.697490e+07  2.9629664  0.6842456
##   1.149757e+08  2.9629664  0.6842456
##   1.519911e+08  2.9629664  0.6842456
##   2.009233e+08  2.9629665  0.6842456
##   2.656088e+08  2.9629665  0.6842456
##   3.511192e+08  2.9629665  0.6842456
##   4.641589e+08  2.9629665  0.6842456
##   6.135907e+08  2.9629665  0.6842456
##   8.111308e+08  2.9629665  0.6842456
##   1.072267e+09  2.9629665  0.6842456
##   1.417474e+09  2.9629665  0.6842456
##   1.873817e+09  2.9629665  0.6842456
##   2.477076e+09  2.9629665  0.6842456
##   3.274549e+09  2.9629665  0.6842456
##   4.328761e+09  2.9629665  0.6842456
##   5.722368e+09  2.9629665  0.6842456
##   7.564633e+09  2.9629665  0.6842456
##   1.000000e+10  2.9629665  0.6842456
## 
## RMSE was used to select the optimal model using  the smallest value.
## The final value used for the model was lambda = 0.01.
{% endhighlight %}



{% highlight r %}
plot(ridge)
{% endhighlight %}

![plot of chunk unnamed-chunk-5](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-5-1.png)

Em seguida, realizamos a predição dos dados, mas agora utilizando os dados de validação. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos. 


{% highlight r %}
ridge.pred <- predict(ridge, dados_validacao[,2:14])

ridge.pred <- data.frame(pred = ridge.pred, obs = dados_validacao$cra)

ggplot(ridge.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
{% endhighlight %}

![plot of chunk unnamed-chunk-6](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-6-1.png)

O RMSE alto indica que o erro na predição foi alto. Ao utlizar a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.449. 


{% highlight r %}
round(defaultSummary(ridge.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
##     RMSE Rsquared 
##    0.449    0.665
{% endhighlight %}

## Modelo de regressão Lasso

Assim como no tópico anterior, criaremos um novo modelo agora utilizando o método Lasso para a seleção de preditores. Após a criação e treinamento do modelo, também realizaremos a predição do mesmo. 


{% highlight r %}
lasso <- train(cra~., data = dados_treino[,2:14],
               method='lasso',
                tuneLength = 10,
               preProcess=c('center', 'scale')
)
{% endhighlight %}

O gráfico abaixo ilustra os 10 valores obtidos para fraction e a relação com seus respectivos RMSE. Em seguida os mesmos valores em detalhes.


{% highlight r %}
plot(lasso)
{% endhighlight %}

![plot of chunk unnamed-chunk-9](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-9-1.png)

{% highlight r %}
lasso
{% endhighlight %}



{% highlight text %}
## The lasso 
## 
## 511 samples
##  12 predictor
## 
## Pre-processing: centered (12), scaled (12) 
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 511, 511, 511, 511, 511, 511, ... 
## Resampling results across tuning parameters:
## 
##   fraction   RMSE       Rsquared 
##   0.1000000  0.8141437  0.5276665
##   0.1888889  0.7557930  0.5766531
##   0.2777778  0.7032861  0.6194808
##   0.3666667  0.6550835  0.6513060
##   0.4555556  0.6108729  0.6726158
##   0.5444444  0.5717756  0.6873726
##   0.6333333  0.5381594  0.6989018
##   0.7222222  0.5107670  0.7071166
##   0.8111111  0.4906253  0.7129157
##   0.9000000  0.4793249  0.7158749
## 
## RMSE was used to select the optimal model using  the smallest value.
## The final value used for the model was fraction = 0.9.
{% endhighlight %}

Para realizar a predição dos dados também utilizamos os dados de validação. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos.


{% highlight r %}
lasso.pred <- predict(lasso, dados_validacao[,2:14])

lasso.pred <- data.frame(pred = lasso.pred, obs = dados_validacao$cra)

ggplot(lasso.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
{% endhighlight %}

![plot of chunk unnamed-chunk-10](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-10-1.png)

Utilizando a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.437. 


{% highlight r %}
round(defaultSummary(lasso.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
##     RMSE Rsquared 
##    0.437    0.663
{% endhighlight %}

## Comparação de modelos

Realizamos a comparação de modelos com base nos valores obtidos no RMSE. Quanto mais baixo o valor, melhor. Abaixo temos os gráficos mostrados anteriormente, agora lado a lado para uma melhor comparação.Vemos que o comportamento nos dados de validação é bem semelhante, os gráficos gerados não apresentam uma diferença perceptível muito significante.


{% highlight r %}
compare <- ridge.pred
compare$model <- "Ridge"
lasso.pred$model <- "Lasso"

compare <- rbind(compare, lasso.pred)

ggplot(compare, aes(x = pred, y = obs)) + 
  geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + 
  facet_grid(. ~ model) + 
  geom_abline() +
  ggtitle("Observado x Previsão (validação)")
{% endhighlight %}

![plot of chunk unnamed-chunk-12](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-12-1.png)

Assim como nos gráficos, o fenômeno se repetiu para os valores de RSME. Ambos são altos e com quase o mesmo valor. Porém, o RMSE do modelo Lasso consegue atingir um menor valor. Podemos então considerar que o melhor modelo é o que utiliza da técnica Lasso. O melhor modelo é aquele que possui o RMSE mais baixo. 


{% highlight r %}
round(defaultSummary(ridge.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
##     RMSE Rsquared 
##    0.449    0.665
{% endhighlight %}



{% highlight r %}
round(defaultSummary(lasso.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
##     RMSE Rsquared 
##    0.437    0.663
{% endhighlight %}

## Importância de variáveis no modelo Lasso

Geramos uma representação gráfica com a importância das variáveis e mais abaixo estão os valores detalhados sobre a importância das mesmas. Vemos que Cálculo 2 é apresentada como a variável de maior importância, seguida por IC e P2. Temos apenas uma variável discartada que foi Física 3, apresentando overall igual a 0. 


{% highlight r %}
plot(varImp(lasso))
{% endhighlight %}

![plot of chunk unnamed-chunk-14](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-14-1.png)

{% highlight r %}
varImp(lasso)
{% endhighlight %}



{% highlight text %}
## loess r-squared variable importance
## 
##           Overall
## Cálculo.2 100.000
## IC         41.837
## P2         25.549
## Discreta   23.305
## P1         18.968
## Grafos     17.809
## Vetorial   14.513
## Cálculo.1  13.001
## LP1        12.518
## LP2         8.069
## LPT         3.667
## Física.3    0.000
{% endhighlight %}

## Re-treino de modelo Lasso com dados de validação

Repetiremos aqui os passos realizados na construção e treino do modelo Lasso. Porém, desta vez estaremos utilizando os dados de validação para treinar o modelo. Segue:


{% highlight r %}
lasso <- train(cra~., data = dados_validacao[,2:14],
               method='lasso',
                tuneLength = 10,
               preProcess=c('center', 'scale'))
{% endhighlight %}

O gráfico abaixo ilustra os 10 valores obtidos para fraction e a relação com seus respectivos RMSE. Em seguida os mesmos valores em detalhes.


{% highlight r %}
plot(lasso)
{% endhighlight %}

![plot of chunk unnamed-chunk-16](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-16-1.png)

{% highlight r %}
lasso
{% endhighlight %}



{% highlight text %}
## The lasso 
## 
## 37 samples
## 12 predictors
## 
## Pre-processing: centered (12), scaled (12) 
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 37, 37, 37, 37, 37, 37, ... 
## Resampling results across tuning parameters:
## 
##   fraction   RMSE       Rsquared 
##   0.1000000  0.5702018  0.6457216
##   0.1888889  0.5076296  0.6046636
##   0.2777778  0.4768178  0.5827288
##   0.3666667  0.4624886  0.5785330
##   0.4555556  0.4655663  0.5696089
##   0.5444444  0.4835833  0.5538252
##   0.6333333  0.5053069  0.5392726
##   0.7222222  0.5311599  0.5230208
##   0.8111111  0.5608953  0.5000516
##   0.9000000  0.5913489  0.4724158
## 
## RMSE was used to select the optimal model using  the smallest value.
## The final value used for the model was fraction = 0.3666667.
{% endhighlight %}

Em seguida, a realização de predição utilizando os mesmos dados. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos.


{% highlight r %}
lasso.pred <- predict(lasso, dados_validacao[,2:14])

lasso.pred <- data.frame(pred = lasso.pred, obs = dados_validacao$cra)

ggplot(lasso.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
{% endhighlight %}

![plot of chunk unnamed-chunk-17](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-17-1.png)

Utilizando a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.454. Ao interpretar o resultado da função entendemos que houve um aumento no valor do RMSE e, consequentemente, uma piora no modelo.


{% highlight r %}
round(defaultSummary(lasso.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
##     RMSE Rsquared 
##    0.454    0.674
{% endhighlight %}

## Tentativa de melhora no modelo

Para tentar melhorar o modelo, vamos tentar uma nova abordagem para imputação de dados. Inicialmente, fazíamos a substituição de valores NA pelo valor do cra. Agora substituiremos esses valores vazios pela média das notas do primeiro período.


{% highlight r %}
dados_treino = read.csv("p1p2.graduados_treino.csv")
dados_validacao = read.csv("p1p2.graduados_validacao.csv")

dados_treino = dados_treino[,2:15]
dados_validacao = dados_validacao[,2:15]

for(i in 1:nrow(dados_treino)){
  for(j in 1:ncol(dados_treino)){
    if(is.na(dados_treino[i,j])){
      dados_treino[i, j] = rowMeans(dados_treino[i,2:13], na.rm = T)
    }
    if(i <= nrow(dados_validacao)){
      if(is.na(dados_validacao[i,j])){
        dados_validacao[i, j] = rowMeans(dados_treino[i,2:13], na.rm = T)
      }
    }
  }
}
{% endhighlight %}

Assim como nos tópicos anteriores, criamos o modelo utlizando os dados de treino.


{% highlight r %}
lasso <- train(cra~., data = dados_treino[,2:14],
               method='lasso',
                tuneLength = 10,
               preProcess=c('center', 'scale'))
{% endhighlight %}

O gráfico abaixo ilustra os 10 valores obtidos para fraction e a relação com seus respectivos RMSE. Em seguida os mesmos valores em detalhes.


{% highlight r %}
plot(lasso)
{% endhighlight %}

![plot of chunk unnamed-chunk-21](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-21-1.png)

{% highlight r %}
lasso
{% endhighlight %}



{% highlight text %}
## The lasso 
## 
## 511 samples
##  12 predictor
## 
## Pre-processing: centered (12), scaled (12) 
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 511, 511, 511, 511, 511, 511, ... 
## Resampling results across tuning parameters:
## 
##   fraction   RMSE       Rsquared 
##   0.1000000  0.8150713  0.4021364
##   0.1888889  0.7729049  0.4584215
##   0.2777778  0.7338854  0.4913313
##   0.3666667  0.6982370  0.5111362
##   0.4555556  0.6666010  0.5237566
##   0.5444444  0.6395067  0.5332335
##   0.6333333  0.6172118  0.5403274
##   0.7222222  0.5999298  0.5463035
##   0.8111111  0.5881088  0.5508598
##   0.9000000  0.5820381  0.5540132
## 
## RMSE was used to select the optimal model using  the smallest value.
## The final value used for the model was fraction = 0.9.
{% endhighlight %}

Em seguida, a realização de predição utilizando os dados de validação. Abaixo temos um gráfico representando a validação do modelo, incluindo a "linha preditora" e resíduos.


{% highlight r %}
lasso.pred <- predict(lasso, dados_validacao[,2:14])

lasso.pred <- data.frame(pred = lasso.pred, obs = dados_validacao$cra)

ggplot(lasso.pred, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "darkred") + ggtitle("Previsão x Observado (validação)")
{% endhighlight %}

![plot of chunk unnamed-chunk-22](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-22-1.png)

Geramos uma representação gráfica com a importância das variáveis e mais abaixo estão os valores detalhados sobre a importância das mesmas. Vemos que Cálculo 2 continua sendo apresentada como a variável de maior importância, seguida por IC e agora Grafos. Temos apenas uma variável discartada que para o novo modelo foi LPT, apresentando overall igual a 0. 


{% highlight r %}
plot(varImp(lasso))
{% endhighlight %}

![plot of chunk unnamed-chunk-23](/AD2/figure/source/lab-2-parte-3/2017-05-15-lab-2-parte-3/unnamed-chunk-23-1.png)

{% highlight r %}
varImp(lasso)
{% endhighlight %}



{% highlight text %}
## loess r-squared variable importance
## 
##           Overall
## Cálculo.2  100.00
## IC          65.81
## Grafos      57.15
## Vetorial    54.07
## P2          48.15
## Discreta    41.75
## P1          29.17
## Cálculo.1   28.00
## LP1         23.17
## Física.3    22.91
## LP2         20.43
## LPT          0.00
{% endhighlight %}

Utilizando a função *round* é fornecido que o RMSE obtido no modelo Ridge foi igual a 0.411. Ao interpretar o resultado da função entendemos que houve uma diminuição no valor do RMSE e, consequentemente, uma melhora no modelo.


{% highlight r %}
round(defaultSummary(lasso.pred), digits = 3)
{% endhighlight %}



{% highlight text %}
##     RMSE Rsquared 
##    0.411    0.670
{% endhighlight %}

## Gerando dados de predição

Para gerar dados de predição utilizamos dados de teste. Realizamos a predição de cra a partir das disciplinas dos dois primeiros semestres. O resultado foi submetido na plataforma Kaggle.


{% highlight r %}
head(dados_teste)
{% endhighlight %}



{% highlight text %}
##                          matricula Cálculo.1 Vetorial LPT  P1  LP1
## 1 037119c4740aa04d14742993e4aab789       8.2      9.1 8.3 7.0 10.0
## 2 0402a824ba0c87f73209cdb49b5072be       5.0      7.7 7.8 8.8  7.1
## 3 075d778a8444ef224757557479320148       5.2      5.0 9.6 7.8  6.2
## 4 09b9a1b335be033c236add2ba699c13f       7.6      6.0 8.7 7.0  8.4
## 5 0d3c0ddcdd2a97627575c27b5d1a058a       8.3      8.1 7.0 8.4  9.4
## 6 107f352e7c2d881c0f5f72a4584cd8fd       5.5      6.9 7.3 7.0  9.1
##    IC Cálculo.2 Discreta  P2 LP2 Grafos Física.3
## 1 7.7       9.2      9.7 9.2 8.9    9.1      9.0
## 2 8.8       7.3      7.3 7.1 7.3    8.0      6.0
## 3 5.4       5.1      5.0 5.7 7.0    7.0      9.3
## 4 7.0       5.0      5.9 7.8 6.0    6.6      5.9
## 5 8.4       7.8      7.9 8.5 8.5    8.0      8.0
## 6 7.4       7.0      7.6 9.4 5.2    8.4      8.8
{% endhighlight %}



{% highlight r %}
dados_teste$cra = NA
dados_teste$cra = predict(lasso, dados_teste)
dados_teste = dados_teste[,c("matricula","cra")]
head(dados_teste)
{% endhighlight %}



{% highlight text %}
##                          matricula      cra
## 1 037119c4740aa04d14742993e4aab789 8.309662
## 2 0402a824ba0c87f73209cdb49b5072be 7.380805
## 3 075d778a8444ef224757557479320148 6.478184
## 4 09b9a1b335be033c236add2ba699c13f 6.809691
## 5 0d3c0ddcdd2a97627575c27b5d1a058a 7.816722
## 6 107f352e7c2d881c0f5f72a4584cd8fd 7.552772
{% endhighlight %}
